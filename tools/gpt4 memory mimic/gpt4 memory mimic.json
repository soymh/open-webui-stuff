[{"id":"gpt4_memory","user_id":"7e9a40d5-a5d7-461c-81eb-91d1973cab1e","name":"GPT4 Memory Mimic","content":"\"\"\"\ntitle: Memory Enhancement Tool for LLM Web UI\nauthor: https://github.com/mhioi\nversion: 1.0.0\nlicense: MIT\n\"\"\"\n\nimport os\nimport json\nfrom typing import Callable, Any\nimport asyncio\nimport datetime\nfrom pydantic import BaseModel, Field\n\n\nclass MemoryFunctions:\n    def __init__(self, memory_file=\"memory.json\", debug=False):\n        self.memory_file = memory_file\n        self.debug = debug\n        self.memory_data = self.load_memory()\n        self.tag_options = [\"personal\", \"work\", \"education\", \"life\", \"person\", \"others\"]\n\n    def switch_memory_file(self, new_file: str):\n        \"\"\"Switches and initializes operations on a new memory FILE;only do if the user indicates a file process.\"\"\"\n        self.memory_file = new_file\n        self.memory_data = self.load_memory()\n        if self.debug:\n            print(f\"Switched to memory file: {self.memory_file}\")\n\n    def reindex_memory(self):\n        if self.debug:\n            print(\"Reindexing memory entries.\")\n\n        # Reindex memory in ascending order\n        sorted_indices = sorted(self.memory_data.keys())\n        reindexed_memory = {\n            new_index + 1: self.memory_data[old_index]\n            for new_index, old_index in enumerate(sorted_indices)\n        }\n        self.memory_data = reindexed_memory\n        self.save_memory()\n\n        return \"Memory reindexed successfully.\"\n\n    def delete_memory_by_index(self, index: int):\n        if index in self.memory_data:\n            del self.memory_data[index]\n            self.save_memory()\n            return f\"Memory index {index} deleted successfully.\"\n        else:\n            return f\"Memory index {index} does not exist.\"\n\n    def update_memory_by_index(self, index: int, tag: str, memo: str, by: str):\n        if index in self.memory_data:\n            if tag not in self.tag_options:\n                tag = \"others\"\n\n            # Update the entry\n            self.memory_data[index][\"tag\"] = tag\n            self.memory_data[index][\"memo\"] = memo\n            self.memory_data[index][\"by\"] = by\n            self.memory_data[index][\"last_modified\"] = datetime.datetime.now().strftime(\n                \"%Y-%m-%d_%H:%M:%S\"\n            )\n            self.save_memory()\n            return f\"Memory index {index} updated successfully.\"\n        else:\n            return f\"Memory index {index} does not exist.\"\n\n    def load_memory(self):\n        if os.path.exists(self.memory_file):\n            if self.debug:\n                print(f\"Loading memory from {self.memory_file}\")\n            with open(self.memory_file, \"r\") as file:\n                return json.load(file)\n        else:\n            return {}\n\n    def save_memory(self):\n        if self.debug:\n            print(f\"Saving memory to {self.memory_file}\")\n        with open(self.memory_file, \"w\") as file:\n            json.dump(self.memory_data, file, ensure_ascii=False, indent=4)\n\n    def add_to_memory(self, tag: str, memo: str, by: str):\n        if tag not in self.tag_options:\n            tag = \"others\"\n\n        index = len(self.memory_data) + 1\n        entry = {\n            \"tag\": tag,\n            \"memo\": memo,\n            \"by\": by,\n            \"last_modified\": datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\"),\n        }\n        self.memory_data[index] = entry\n        self.save_memory()\n\n    # Other methods remain unchanged...\n    def retrieve_from_memory(self, key: str):\n        if self.debug:\n            print(f\"Retrieving from memory: {key}\")\n        return self.memory_data.get(key, None)\n\n    def process_input_for_memory(self, input_text: str):\n        return {\"timestamp\": str(datetime.datetime.now()), \"input\": input_text}\n\n    def get_all_memories(self) -> dict:\n        if self.debug:\n            print(\"Retrieving all memories.\")\n        return self.memory_data\n\n    def clear_memory(self):\n        if self.debug:\n            print(\"Clearing all memory entries.\")\n        self.memory_data.clear()\n        self.save_memory()\n        return \"ALL MEMORIES CLEARED!\"\n\n\nclass EventEmitter:\n    def __init__(self, event_emitter: Callable[[dict], Any] = None):\n        self.event_emitter = event_emitter\n\n    async def emit(self, description=\"Unknown state\", status=\"in_progress\", done=False):\n        if self.event_emitter:\n            await self.event_emitter(\n                {\n                    \"type\": \"status\",\n                    \"data\": {\n                        \"status\": status,\n                        \"description\": description,\n                        \"done\": done,\n                    },\n                }\n            )\n\n\nclass Tools:\n    class Valves(BaseModel):\n        USE_MEMORY: bool = Field(\n            default=True, description=\"Enable or disable memory usage.\"\n        )\n        MEMORY_REFRESH_INTERVAL: int = Field(\n            default=60,\n            description=\"Interval in minutes to refresh and analyze memory data.\",\n        )\n        DEBUG: bool = Field(default=True, description=\"Enable or disable debug mode.\")\n\n    def __init__(self):\n        self.valves = self.Valves()\n        self.memory = MemoryFunctions(debug=self.valves.DEBUG)\n        self.confirmation_pending = False\n\n    async def handle_input(\n        self,\n        input_text: str,\n        tag: str,\n        user_wants_to_add: bool,\n        llm_wants_to_add: bool,\n        by: str,\n        __event_emitter__: Callable[[dict], Any] = None,\n    ) -> str:\n        \"\"\"\n        AUTOMATICALLY Summarize user input and enhance responses using memory data.\n\n        :params input_text: The TEXT .\n        :returns: The response considering memory data.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n\n        if self.valves.DEBUG:\n            print(f\"Handling input: {input_text}\")\n\n        await emitter.emit(f\"Analyzing input for memory: {input_text}\")\n\n        if self.valves.USE_MEMORY:\n            # Assume 'by' is determined outside and 'tag' is selected by LLM\n            if tag not in self.memory.tag_options:\n                tag = \"others\"\n\n            if user_wants_to_add:\n                await emitter.emit(\n                    description=f\"User requested to add to memory with tag {tag}\",\n                    status=\"memory_update\",\n                    done=False,\n                )\n                self.memory.add_to_memory(tag, input_text, \"user\")\n                return \"added to memory by user's request!\"\n            elif llm_wants_to_add:\n                await emitter.emit(\n                    description=f\"LLM added to memory with tag {tag}\",\n                    status=\"memory_update\",\n                    done=False,\n                )\n                self.memory.add_to_memory(tag, input_text, \"LLM\")\n                return \"added to memory by LLM's request!\"\n\n        # The remaining logic stays the same.\n\n    async def recall_memories(\n        self, __event_emitter__: Callable[[dict], Any] = None\n    ) -> str:\n        \"\"\"\n        Retrieve all stored memories in current file and provide them to the user.\n\n        :return: A structured representation of all memory contents.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n        await emitter.emit(\n            \"Retrieving all stored memories.\", status=\"recall_in_progress\"\n        )\n\n        all_memories = self.memory.get_all_memories()\n        if not all_memories:\n            message = \"No memory stored.\"\n            if self.valves.DEBUG:\n                print(message)\n            await emitter.emit(\n                description=message,\n                status=\"recall_complete\",\n                done=True,\n            )\n            return json.dumps({\"message\": message}, ensure_ascii=False)\n\n        # Correctly format stored memories contents for readability\n        formatted_memories = json.dumps(all_memories, ensure_ascii=False, indent=4)\n\n        if self.valves.DEBUG:\n            print(f\"All stored memories retrieved: {formatted_memories}\")\n\n        await emitter.emit(\n            description=f\"All stored memories retrieved: {formatted_memories}\",\n            status=\"recall_complete\",\n            done=True,\n        )\n\n        return f\"Memories are : {formatted_memories}\"\n\n    async def clear_memories(\n        self, user_confirmation: bool, __event_emitter__: Callable[[dict], Any] = None\n    ) -> str:\n        \"\"\"\n        Clear all stored memories in current file after user confirmation;ask twice the user for confimation.\n\n        :param user_confirmation: Boolean indicating user confirmation to clear memories.\n        :return: A message indicating the status of the operation.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n        await emitter.emit(\n            \"Attempting to clear all memory entries.\", status=\"clear_memory_attempt\"\n        )\n\n        if self.confirmation_pending and user_confirmation:\n            self.memory.clear_memory()\n            await emitter.emit(\n                description=\"All memory entries have been cleared.\",\n                status=\"clear_memory_complete\",\n                done=True,\n            )\n            self.confirmation_pending = False\n            return json.dumps(\n                {\"message\": \"All memory entries cleared.\"}, ensure_ascii=False\n            )\n\n        if not self.confirmation_pending:\n            self.confirmation_pending = True\n            await emitter.emit(\n                description=\"Please confirm that you want to clear all memories. Call this function again with confirmation.\",\n                status=\"confirmation_required\",\n                done=False,\n            )\n            return json.dumps(\n                {\"message\": \"Please confirm to clear all memories.\"}, ensure_ascii=False\n            )\n\n        await emitter.emit(\n            description=\"Clear memory operation aborted.\",\n            status=\"clear_memory_aborted\",\n            done=True,\n        )\n        self.confirmation_pending = False\n        return json.dumps(\n            {\"message\": \"Memory clear operation aborted.\"}, ensure_ascii=False\n        )\n\n    async def refresh_memory(self, __event_emitter__: Callable[[dict], Any] = None):\n        \"\"\"\n        Periodically refresh and optimize memory data, includes reindexing.\n\n        :returns: A message indicating the status of the refresh operation.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n        await emitter.emit(\"Starting memory refresh process.\")\n\n        if self.valves.DEBUG:\n            print(\"Refreshing memory...\")\n\n        if self.valves.USE_MEMORY:\n            refresh_message = self.memory.reindex_memory()\n\n            if self.valves.DEBUG:\n                print(refresh_message)\n\n            await emitter.emit(\n                description=refresh_message, status=\"memory_refresh\", done=True\n            )\n\n            return refresh_message\n\n        if self.valves.DEBUG:\n            print(\"Memory refreshed.\")\n\n        await emitter.emit(\n            status=\"complete\", description=\"Memory refresh completed.\", done=True\n        )\n\n    async def update_memory_entry(\n        self,\n        index: int,\n        tag: str,\n        memo: str,\n        by: str,\n        __event_emitter__: Callable[[dict], Any] = None,\n    ) -> str:\n        \"\"\"\n        Update an existing memory entry based on its index.\n\n        :param index: The index of the memory entry to update,STARTING FROM 1.\n        :param tag: The tag for the memory entry.\n        :param memo: The memory information to update.\n        :param by: Who is making the update ('user' or 'LLM').\n        :returns: A message indicating the success or failure of the update.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n\n        if self.valves.DEBUG:\n            print(\n                f\"Updating memory index {index} with tag: {tag}, memo: {memo}, by: {by}\"\n            )\n\n        update_message = self.memory.update_memory_by_index(index, tag, memo, by)\n\n        await emitter.emit(\n            description=update_message, status=\"memory_update\", done=True\n        )\n\n        return update_message\n\n    async def add_multiple_memories(\n        self,\n        memory_entries: list,\n        llm_wants_to_add: bool,\n        __event_emitter__: Callable[[dict], Any] = None,\n    ) -> str:\n        \"\"\"\n        Allows the LLM to add multiple memory entries at once.\n\n        :param memory_entries: A list of dictionary entries, each containing tag, memo, by.Usage Example: memory_entries = [{\"tag\": \"personal\", \"memo\": \"This is a personal note\", \"by\": \"LLM\"},{\"tag\": \"work\", \"memo\": \"Project deadline is tomorrow\", \"by\": \"LLM\"}]\n        :param llm_wants_to_add: Boolean indicating LLM's desire to add the memories.\n        :returns: A message indicating the success or failure of the operations.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n        responses = []\n\n        if not llm_wants_to_add:\n            return \"LLM has not requested to add multiple memories.\"\n\n        for idx, entry in enumerate(memory_entries):\n            tag = entry.get(\"tag\", \"others\")\n            memo = entry.get(\"memo\", \"\")\n            by = entry.get(\"by\", \"LLM\")\n\n            if tag not in self.memory.tag_options:\n                tag = \"others\"\n\n            if self.valves.DEBUG:\n                print(f\"Adding memory {idx+1}: tag={tag}, memo={memo}, by={by}\")\n\n            # Add the memory\n            self.memory.add_to_memory(tag, memo, by)\n            response = f\"Memory {idx+1} added with tag {tag} by {by}.\"\n            responses.append(response)\n\n            await emitter.emit(description=response, status=\"memory_update\", done=False)\n\n        await emitter.emit(\n            description=\"All requested memories have been processed.\",\n            status=\"memory_update_complete\",\n            done=True,\n        )\n\n        return \"\\n\".join(responses)\n\n    async def delete_memory_entry(\n        self,\n        index: int,\n        llm_wants_to_delete: bool,\n        __event_emitter__: Callable[[dict], Any] = None,\n    ) -> str:\n        \"\"\"\n        Delete a memory entry based on its index.\n\n        :param index: The index of the memory entry to delete,STARTING FROM 1.\n        :param llm_wants_to_delete: Boolean indicating if the LLM has requested the deletion.\n        :returns: A message indicating the success or failure of the deletion.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n\n        if not llm_wants_to_delete:\n            return \"LLM has not requested to delete a memory.\"\n\n        if self.valves.DEBUG:\n            print(f\"Attempting to delete memory at index {index}\")\n\n        deletion_message = self.memory.delete_memory_by_index(index)\n\n        await emitter.emit(\n            description=deletion_message, status=\"memory_deletion\", done=True\n        )\n\n        return deletion_message\n\n    async def delete_multiple_memories(\n        self,\n        indices: list,\n        llm_wants_to_delete: bool,\n        __event_emitter__: Callable[[dict], Any] = None,\n    ) -> str:\n        \"\"\"\n        Delete multiple memory entries based on their indices.\n\n        :param indices: A list of indices of the memory entries to delete,STARTING FROM 1.\n        :param llm_wants_to_delete: Boolean indicating if the LLM has requested the deletions.\n        :returns: A message indicating the success or failure of the deletions.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n        responses = []\n\n        if not llm_wants_to_delete:\n            return \"LLM has not requested to delete multiple memories.\"\n\n        for index in indices:\n            if self.valves.DEBUG:\n                print(f\"Attempting to delete memory at index {index}\")\n\n            deletion_message = self.memory.delete_memory_by_index(index)\n            responses.append(deletion_message)\n\n            await emitter.emit(\n                description=deletion_message, status=\"memory_deletion\", done=False\n            )\n\n        await emitter.emit(\n            description=\"All requested memory deletions have been processed.\",\n            status=\"memory_deletion_complete\",\n            done=True,\n        )\n\n        return \"\\n\".join(responses)\n\n    async def create_or_switch_memory_file(\n        self, new_file_name: str, __event_emitter__: Callable[[dict], Any] = None\n    ) -> str:\n        \"\"\"\n        Create a new memory file or switch to an existing one.\n\n        :param new_file_name: The name of the new or existing memory file.\n        :returns: A message indicating the success or failure of the operation.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n\n        if self.valves.DEBUG:\n            print(f\"Switching to or creating memory file: {new_file_name}\")\n\n        self.memory.switch_memory_file(new_file_name + \".json\")\n\n        message = f\"Memory file switched to {new_file_name}.\"\n\n        await emitter.emit(description=message, status=\"file_switching\", done=True)\n\n        return message\n\n    async def list_memory_files(\n        self, __event_emitter__: Callable[[dict], Any] = None\n    ) -> str:\n        \"\"\"\n        List available memory files in the current directory.\n\n        :returns: A message with the list of available memory files.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n        memory_files = []\n\n        if self.valves.DEBUG:\n            print(\"Listing memory files in current directory: \")\n\n        try:\n            for file in os.listdir(\".\"):\n                if file.endswith(\".json\"):\n                    if self.valves.DEBUG:\n                        print(f\"Found memory file: {file}\")\n                    memory_files.append(file)\n\n            description = \"Available memory files: \" + \", \".join(memory_files)\n            status = \"file_listing_complete\"\n\n        except Exception as e:\n            description = f\"Error accessing directory: {str(e)}\"\n            status = \"file_listing_error\"\n\n        await emitter.emit(description=description, status=status, done=True)\n\n        return description\n\n    async def current_memory_file(\n        self, __event_emitter__: Callable[[dict], Any] = None\n    ) -> str:\n        \"\"\"\n        Retrieve the name of the currently active memory file.\n\n        :returns: A message indicating the current memory file.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n\n        current_file = self.memory.memory_file\n\n        message = f\"Currently using memory file: {current_file}\"\n\n        if self.valves.DEBUG:\n            print(message)\n\n        await emitter.emit(\n            description=message, status=\"current_file_retrieved\", done=True\n        )\n\n        return message\n\n    async def delete_memory_file(\n        self,\n        file_to_delete: str,\n        user_confirmation: bool,\n        __event_emitter__: Callable[[dict], Any] = None,\n    ) -> str:\n        \"\"\"\n        Delete a memory file with confirmation and necessary file switching.\n\n        :param file_to_delete: The name of the memory file to delete.\n        :param user_confirmation: Boolean indicating user confirmation for deletion.\n        :returns: A message indicating the success or failure of the deletion.\n        \"\"\"\n        emitter = EventEmitter(__event_emitter__)\n        available_files = [f for f in os.listdir(\".\") if f.endswith(\".json\")]\n\n        if file_to_delete not in available_files:\n            message = f\"File '{file_to_delete}' does not exist.\"\n            await emitter.emit(description=message, status=\"file_not_found\", done=True)\n            if self.valves.DEBUG:\n                print(message)\n            return message\n\n        if self.confirmation_pending and user_confirmation:\n            try:\n                if self.memory.memory_file == file_to_delete:\n                    # Switch to another file before deleting the current one\n                    alternative_file = next(\n                        (f for f in available_files if f != file_to_delete), None\n                    )\n                    if not alternative_file:\n                        message = (\n                            \"No alternative memory file to switch to. Deletion aborted.\"\n                        )\n                        await emitter.emit(\n                            description=message, status=\"no_alternative_file\", done=True\n                        )\n                        if self.valves.DEBUG:\n                            print(message)\n                        return message\n\n                    self.memory.switch_memory_file(alternative_file)\n                    switch_message = f\"Switched to '{alternative_file}'. Now deleting '{file_to_delete}'.\"\n                    await emitter.emit(\n                        description=switch_message, status=\"file_switched\", done=False\n                    )\n                    if self.valves.DEBUG:\n                        print(switch_message)\n\n                os.remove(file_to_delete)\n                message = f\"File '{file_to_delete}' deleted successfully.\"\n                status = \"file_deletion_complete\"\n            except Exception as e:\n                message = f\"Error deleting file '{file_to_delete}': {str(e)}\"\n                status = \"deletion_error\"\n\n            await emitter.emit(description=message, status=status, done=True)\n            self.confirmation_pending = False\n            return message\n\n        if not self.confirmation_pending:\n            self.confirmation_pending = True\n            confirmation_message = (\n                \"Please confirm that you want to delete the memory file. \"\n                \"Call this function again with confirmation.\"\n            )\n            await emitter.emit(\n                description=confirmation_message,\n                status=\"confirmation_required\",\n                done=False,\n            )\n            return json.dumps(\n                {\n                    \"message\": \"Please confirm to delete the memory file.\",\n                    \"file\": file_to_delete,\n                },\n                ensure_ascii=False,\n            )\n\n        await emitter.emit(\n            description=\"Deletion of memory file aborted.\",\n            status=\"deletion_aborted\",\n            done=True,\n        )\n        self.confirmation_pending = False\n        return json.dumps(\n            {\"message\": \"Memory file deletion aborted.\", \"file\": file_to_delete},\n            ensure_ascii=False,\n        )\n","specs":[{"name":"add_multiple_memories","description":"Allows the LLM to add multiple memory entries at once.","parameters":{"type":"object","properties":{"memory_entries":{"type":"list","description":"A list of dictionary entries, each containing tag, memo, by.Usage Example: memory_entries = [{\"tag\": \"personal\", \"memo\": \"This is a personal note\", \"by\": \"LLM\"},{\"tag\": \"work\", \"memo\": \"Project deadline is tomorrow\", \"by\": \"LLM\"}]"},"llm_wants_to_add":{"type":"bool","description":"Boolean indicating LLM's desire to add the memories."}},"required":["memory_entries","llm_wants_to_add"]}},{"name":"clear_memories","description":"Clear all stored memories in current file after user confirmation;ask twice the user for confimation.","parameters":{"type":"object","properties":{"user_confirmation":{"type":"bool","description":"Boolean indicating user confirmation to clear memories."}},"required":["user_confirmation"]}},{"name":"create_or_switch_memory_file","description":"Create a new memory file or switch to an existing one.","parameters":{"type":"object","properties":{"new_file_name":{"type":"str","description":"The name of the new or existing memory file."}},"required":["new_file_name"]}},{"name":"current_memory_file","description":"Retrieve the name of the currently active memory file.","parameters":{"type":"object","properties":{},"required":[]}},{"name":"delete_memory_entry","description":"Delete a memory entry based on its index.","parameters":{"type":"object","properties":{"index":{"type":"int","description":"The index of the memory entry to delete,STARTING FROM 1."},"llm_wants_to_delete":{"type":"bool","description":"Boolean indicating if the LLM has requested the deletion."}},"required":["index","llm_wants_to_delete"]}},{"name":"delete_memory_file","description":"Delete a memory file with confirmation and necessary file switching.","parameters":{"type":"object","properties":{"file_to_delete":{"type":"str","description":"The name of the memory file to delete."},"user_confirmation":{"type":"bool","description":"Boolean indicating user confirmation for deletion."}},"required":["file_to_delete","user_confirmation"]}},{"name":"delete_multiple_memories","description":"Delete multiple memory entries based on their indices.","parameters":{"type":"object","properties":{"indices":{"type":"list","description":"A list of indices of the memory entries to delete,STARTING FROM 1."},"llm_wants_to_delete":{"type":"bool","description":"Boolean indicating if the LLM has requested the deletions."}},"required":["indices","llm_wants_to_delete"]}},{"name":"handle_input","description":"AUTOMATICALLY Summarize user input and enhance responses using memory data.","parameters":{"type":"object","properties":{"input_text":{"type":"str","description":"input_text"},"tag":{"type":"str","description":"tag"},"user_wants_to_add":{"type":"bool","description":"user_wants_to_add"},"llm_wants_to_add":{"type":"bool","description":"llm_wants_to_add"},"by":{"type":"str","description":"by"}},"required":["input_text","tag","user_wants_to_add","llm_wants_to_add","by"]}},{"name":"list_memory_files","description":"List available memory files in the current directory.","parameters":{"type":"object","properties":{},"required":[]}},{"name":"recall_memories","description":"Retrieve all stored memories in current file and provide them to the user.","parameters":{"type":"object","properties":{},"required":[]}},{"name":"refresh_memory","description":"Periodically refresh and optimize memory data, includes reindexing.","parameters":{"type":"object","properties":{},"required":[]}},{"name":"update_memory_entry","description":"Update an existing memory entry based on its index.","parameters":{"type":"object","properties":{"index":{"type":"int","description":"The index of the memory entry to update,STARTING FROM 1."},"tag":{"type":"str","description":"The tag for the memory entry."},"memo":{"type":"str","description":"The memory information to update."},"by":{"type":"str","description":"Who is making the update ('user' or 'LLM')."}},"required":["index","tag","memo","by"]}}],"meta":{"description":"a tool for the llm to mimic the gpt4's memory consideration","manifest":{"title":"Memory Enhancement Tool for LLM Web UI","author":"https://github.com/mhioi","version":"1.0.0","license":"MIT"}},"updated_at":1729277465,"created_at":1729078005}]
